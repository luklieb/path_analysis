{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "geological-millennium",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.widgets import Slider\n",
    "from functools import partial\n",
    "from sklearn.decomposition import PCA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "pretty-afternoon",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change matplotlib backend to one that you like\n",
    "# ipympl works well interactively in VSCode\n",
    "# qt otherwise\n",
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "electric-bachelor",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = pd.read_csv('path.csv')\n",
    "tracker = pd.read_csv('tracker.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "299d8b48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "path info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 145841 entries, 0 to 145840\n",
      "Data columns (total 6 columns):\n",
      " #   Column      Non-Null Count   Dtype  \n",
      "---  ------      --------------   -----  \n",
      " 0   Unnamed: 0  145841 non-null  int64  \n",
      " 1   index       145841 non-null  int64  \n",
      " 2   x_pth       145841 non-null  float64\n",
      " 3   y_pth       145841 non-null  float64\n",
      " 4   z_pth       145841 non-null  float64\n",
      " 5   t_pth       145841 non-null  int64  \n",
      "dtypes: float64(3), int64(3)\n",
      "memory usage: 6.7 MB\n",
      "tracker info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 546943 entries, 0 to 546942\n",
      "Data columns (total 6 columns):\n",
      " #   Column      Non-Null Count   Dtype  \n",
      "---  ------      --------------   -----  \n",
      " 0   Unnamed: 0  546943 non-null  int64  \n",
      " 1   index       546943 non-null  int64  \n",
      " 2   x_trk       546943 non-null  float64\n",
      " 3   y_trk       546943 non-null  float64\n",
      " 4   z_trk       546943 non-null  float64\n",
      " 5   t_trk       546943 non-null  int64  \n",
      "dtypes: float64(3), int64(3)\n",
      "memory usage: 25.0 MB\n",
      "path first entries:\n",
      "   Unnamed: 0  index  x_pth  y_pth         z_pth                t_pth\n",
      "0           0    177  450.0  700.0  1.136868e-13  1633969004350000000\n",
      "1           1    178  450.0  700.0  0.000000e+00  1633969004400000000\n",
      "2           2    179  450.0  700.0  0.000000e+00  1633969004450000000\n",
      "3           3    180  450.0  700.0  0.000000e+00  1633969004500000000\n",
      "4           4    181  450.0  700.0  0.000000e+00  1633969004550000000\n",
      "5           5    182  450.0  700.0  0.000000e+00  1633969004600000000\n",
      "6           6    183  450.0  700.0  0.000000e+00  1633969004650000000\n",
      "7           7    184  450.0  700.0  0.000000e+00  1633969004700000000\n",
      "8           8    185  450.0  700.0  0.000000e+00  1633969004750000000\n",
      "9           9    186  450.0  700.0  0.000000e+00  1633969004800000000\n",
      "tracker first entries:\n",
      "   Unnamed: 0  index      x_trk      y_trk        z_trk                t_trk\n",
      "0           0   3180 -36.507133 -40.170982 -2915.784424  1633969004633871000\n",
      "1           1   3181 -36.543438 -40.260765 -2915.713623  1633969004648860000\n",
      "2           2   3182 -36.645119 -40.364326 -2915.732910  1633969004662330000\n",
      "3           3   3183 -36.709301 -40.413754 -2915.772949  1633969004674115000\n",
      "4           4   3184 -36.720108 -40.421989 -2915.788086  1633969004687849000\n",
      "5           5   3185 -36.724915 -40.427578 -2915.725586  1633969004699959000\n",
      "6           6   3186 -36.668312 -40.436436 -2915.676758  1633969004713613000\n",
      "7           7   3187 -36.652710 -40.457592 -2915.729492  1633969004730045000\n",
      "8           8   3188 -36.705055 -40.492893 -2915.809814  1633969004741991000\n",
      "9           9   3189 -36.777580 -40.530525 -2915.860596  1633969004754114000\n",
      "path last entries:\n",
      "        Unnamed: 0   index       x_pth       y_pth  z_pth                t_pth\n",
      "145831      145831  146008  452.842457  701.562654    0.0  1633976295900000000\n",
      "145832      145832  146009  447.406042  705.512440    0.0  1633976295950000000\n",
      "145833      145833  146010  452.304550  700.912436    0.0  1633976296000000000\n",
      "145834      145834  146011  449.915399  706.732001    0.0  1633976296050000000\n",
      "145835      145835  146012  447.821665  700.799745    0.0  1633976296100000000\n",
      "145836      145836  146013  453.334420  703.830407    0.0  1633976296150000000\n",
      "145837      145837  146014  447.203772  705.241272    0.0  1633976296200000000\n",
      "145838      145838  146015  448.839749  700.206254    0.0  1633976296250000000\n",
      "145839      145839  146016  451.547190  706.356472    0.0  1633976296300000000\n",
      "145840      145840  146017  448.090271  700.594083    0.0  1633976296350000000\n",
      "tracker last entries:\n",
      "        Unnamed: 0   index      x_trk      y_trk        z_trk  \\\n",
      "546933      546933  550113 -36.874657 -30.809038 -2912.166748   \n",
      "546934      546934  550114 -36.700726 -29.833389 -2911.989990   \n",
      "546935      546935  550115 -36.479523 -28.752605 -2911.753662   \n",
      "546936      546936  550116 -36.261326 -27.567085 -2911.441650   \n",
      "546937      546937  550117 -36.008144 -26.304020 -2911.068115   \n",
      "546938      546938  550118 -35.735081 -24.971382 -2910.671631   \n",
      "546939      546939  550119 -35.476555 -23.567873 -2910.265625   \n",
      "546940      546940  550120 -35.200634 -22.105921 -2909.841064   \n",
      "546941      546941  550121 -34.895008 -20.589333 -2909.393311   \n",
      "546942      546942  550122 -34.612679 -19.015917 -2908.931641   \n",
      "\n",
      "                      t_trk  \n",
      "546933  1633976297608420000  \n",
      "546934  1633976297620964000  \n",
      "546935  1633976297634683000  \n",
      "546936  1633976297648541000  \n",
      "546937  1633976297661519000  \n",
      "546938  1633976297674323000  \n",
      "546939  1633976297688051000  \n",
      "546940  1633976297701103000  \n",
      "546941  1633976297713388000  \n",
      "546942  1633976297727091000  \n",
      "Diff for same index: 149.866129 sec\n",
      "Num entries in tracker is 3.7502691287086622 times larger than path\n"
     ]
    }
   ],
   "source": [
    "# Quick overviews\n",
    "print(f\"path info:\")\n",
    "path.info()\n",
    "print(f\"tracker info:\")\n",
    "tracker.info()\n",
    "print(f\"path first entries:\", f\"{path.iloc[:10]}\", sep='\\n')\n",
    "print(f\"tracker first entries:\", f\"{tracker.iloc[:10]}\", sep='\\n')\n",
    "print(f\"path last entries:\", f\"{path.iloc[-10:]}\", sep='\\n')\n",
    "print(f\"tracker last entries:\", f\"{tracker.iloc[-10:]}\", sep='\\n')\n",
    "# index==3180 first entry in index column that's the same for both path and tracker datasets \n",
    "t_diff_same_index = (path.loc[path['index'] == 3180]['t_pth'].values[0] - tracker.loc[tracker['index'] == 3180]['t_trk'].values[0])*1e-9\n",
    "print(f\"Diff for same index: {t_diff_same_index} sec\")\n",
    "# Not sure what the 'index' column is for...\n",
    "print(f\"Num entries in tracker is {len(tracker)/len(path)} times larger than path\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "super-geneva",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unifiy colum names\n",
    "column_names = ['unnamed', 'index', 'x', 'y', 'z', 't']\n",
    "path.columns = column_names\n",
    "tracker.columns = column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b59c7bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global values for slicing\n",
    "START = 0\n",
    "END = 100\n",
    "SKIP = 50\n",
    "TAILLENGTH = 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b9a972c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def df_mean_of_diffs(df, column, scale=1):\n",
    "    tdata = df[[column]]\n",
    "    diff = tdata.diff()\n",
    "    return diff.mean().values[0]*scale\n",
    "\n",
    "def df_var_of_diffs(df, column, scale=1):\n",
    "    tdata = df[[column]]\n",
    "    diff = tdata.diff()\n",
    "    return diff.var().values[0]*scale\n",
    "\n",
    "def df_start(df, column, scale=1):\n",
    "    return df[[column]].iloc[0].values[0]*scale\n",
    "\n",
    "def df_end(df, column, scale=1):\n",
    "    return df[[column]].iloc[-1].values[0]*scale\n",
    "    \n",
    "def df_min(df, column, scale=1):\n",
    "    return df[[column]].min().values[0]*scale\n",
    "\n",
    "def df_max(df, column, scale=1):\n",
    "    return df[[column]].max().values[0]*scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "102a993b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time step path: 0.05 sec, var: 0.0\n",
      "time step tracker: 0.0133343082447499 sec, var: 1565.1635220479013\n",
      "start time path: 1633969004.3500001 sec, end: 1633976296.3500001 sec\n",
      "start time tracker based on path: 0.2838711738586426 sec, end: 1.3770909309387207 sec\n",
      "min of tracker timestamp diff: 0.0036330000000000004 sec, max: 0.07236300000000001 sec\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Looks like nano sec resolution (1e-9) with unix epoch 1/1/1970\n",
    "print(f'time step path: {df_mean_of_diffs(path, \"t\", 1e-9 )} sec, var: {df_var_of_diffs(path, \"t\", 1e-9)}')\n",
    "print(f'time step tracker: {df_mean_of_diffs(tracker, \"t\", 1e-9 )} sec, var: {df_var_of_diffs(tracker, \"t\", 1e-9)}')\n",
    "\n",
    "# Variance of tracker timestamps is not null, so investigate further\n",
    "\n",
    "start_time_path = df_start(path, \"t\", 1e-9)\n",
    "end_time_path = df_end(path, \"t\", 1e-9)\n",
    "print(f'start time path: {start_time_path} sec, end: {end_time_path} sec')\n",
    "print(f'start time tracker based on path: {df_start(tracker, \"t\", 1e-9)-start_time_path} sec, end: {df_end(tracker, \"t\", 1e-9)-end_time_path} sec')\n",
    "\n",
    "# Something weird is going on with the timestamp of the tracker data\n",
    "# Let's keep digging\n",
    "print(f'min of tracker timestamp diff: {tracker[[\"t\"]].diff().min().values[0]*1e-9} sec, max: {tracker[[\"t\"]].diff().max().values[0]*1e-9} sec')\n",
    "\n",
    "# tracker time steps are between 0.0036 sec and 0.072 sec\n",
    "# path time steps are constant   0.05 sec\n",
    "# Both datasets start at roughly the same time (+0.28 sec) and end roughly at the same time (+1.38 sec)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "impaired-field",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO add type hints for all functions\n",
    "\n",
    "def get_data_slices(df, start, end, skip):\n",
    "    \"\"\" Slices pandas dataframe\n",
    "    :param df: pandas dataframe\n",
    "    :param start: index\n",
    "    :param end: index\n",
    "    :param skip: samples to skip\n",
    "    :return: tuple of sliced data from x, y, z, t column\n",
    "    \"\"\"\n",
    "    if start <= 0:\n",
    "        start = 0\n",
    "    xdata = df[['x']].iloc[start:end:skip]\n",
    "    ydata = df[['y']].iloc[start:end:skip]\n",
    "    zdata = df[['z']].iloc[start:end:skip]\n",
    "    tdata = df[['t']].iloc[start:end:skip]\n",
    "    return xdata, ydata, zdata, tdata\n",
    "\n",
    "# computationally intense...\n",
    "# Either cache some timestamps, or since timestamps are already sorted\n",
    "# memorize them, so we can use them in future calls as 'quick' known\n",
    "# entry points / hints. \n",
    "#@cache available in >= 3.9\n",
    "# !!! cache only works with the same df for now...\n",
    "# Now deprecated, because data was filtered by timestamps\n",
    "def find_closest_timestamp(df, timestamp, _cache = {}):\n",
    "    if timestamp in _cache:\n",
    "        id = _cache[timestamp]\n",
    "    else:\n",
    "        id = df[['t']].sub(timestamp).abs().idxmin().values[0]\n",
    "        _cache[timestamp] = id\n",
    "\n",
    "    return id\n",
    "\n",
    "def update_plot(slider, time_step, path, tracker, val):\n",
    "    \"\"\" Callback function for interactive 3d plot\n",
    "    :param slider: matplotlib slider object (bound)\n",
    "    :param time_step: time resolution to convert returned slider number to index (bound)\n",
    "    :param path: data of path (bound)\n",
    "    :param tracker: data of tracker (bound)\n",
    "    :val: required by matplotlib, currently not used\n",
    "    \"\"\"\n",
    "    path_index = int(slider.val / time_step)\n",
    "    path_start = int(path_index - TAILLENGTH/time_step)\n",
    "    slice_path = get_data_slices(path, path_start, path_index, SKIP)\n",
    "    # because t_steps are different, we have to look for the\n",
    "    # correct index corresponding to path ind's\n",
    "    #tracker_index = find_closest_timestamp(tracker, path[['t']].iloc[path_index].values[0])\n",
    "    tracker_index = path_index\n",
    "    tracker_start = path_start\n",
    "    slice_tracker = get_data_slices(tracker, tracker_start, tracker_index, SKIP)\n",
    "    ax3d.clear()\n",
    "    #ax3d.scatter3D(slice_path[0], slice_path[1], slice_path[2], c='blue', cmap='hsv')\n",
    "    #ax3d.scatter3D(slice_tracker[0], slice_tracker[1], slice_tracker[2], c='red', cmap='hsv')\n",
    "    ax3d.scatter3D(slice_path[0], slice_path[1], slice_path[2], c=slice_path[3], cmap='Blues')\n",
    "    ax3d.scatter3D(slice_tracker[0], slice_tracker[1], slice_tracker[2], c=slice_tracker[3], cmap='Reds')\n",
    "    fig.canvas.draw()\n",
    "    fig.canvas.draw()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7d4e915b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "path time stamps are ordered: True\n",
      "tracker tiem stamps are ordered: True\n",
      "\n",
      "145835\n",
      "145835\n"
     ]
    }
   ],
   "source": [
    "print(f\"path time stamps are ordered: {path['t'].is_monotonic_increasing}\")\n",
    "print(f\"tracker tiem stamps are ordered: {tracker['t'].is_monotonic_increasing}\")\n",
    "print()\n",
    "\n",
    "# Merge tracker data with path data -> for each path timestamp find closest tracker timestamp and merge those two rows\n",
    "# Gets rid of unnecessary samples in tracker\n",
    "# Choose only columns related to tracker samples and rename the columns\n",
    "tracker_filtered = pd.merge_asof(path.iloc[6:], tracker, \"t\", suffixes=('_path', '_tracker'))\n",
    "tracker_filtered = tracker_filtered[['unnamed_tracker', 'index_tracker',  'x_tracker', 'y_tracker', 'z_tracker', 't']]\n",
    "tracker_filtered.columns = column_names\n",
    "\n",
    "# Can't find closest time stamp for first 6 samples\n",
    "# TODO causes SettingWithCopyWarning later on in sub_mean()...\n",
    "path_filtered = path.iloc[6:,:]\n",
    "\n",
    "print(len(path_filtered))\n",
    "print(len(tracker_filtered))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "naughty-coast",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Can't move this block into a function because then data\n",
    "# in plot isn't updated anymore... \n",
    "fig = plt.figure()\n",
    "ax = plt.subplot(111, label='a')\n",
    "fig.subplots_adjust(left=0.25, bottom=0.25)\n",
    "ax3d = plt.axes(projection='3d', label='b')\n",
    "ax3d.set_xlabel('x')\n",
    "ax3d.set_ylabel('y')\n",
    "ax3d.set_zlabel('z')\n",
    "\n",
    "plt.title('Raw data')\n",
    "\n",
    "t_bias = df_start(path, \"t\", 1e-9)\n",
    "t_end = (df_end(path, \"t\", 1e-9) - t_bias)\n",
    "t_step = df_mean_of_diffs(path, \"t\", 1e-9 )\n",
    "\n",
    "ax_time = plt.axes([0.25, 0.1, 0.65, 0.03])\n",
    "slider = Slider(ax_time, 'Time [sec]', 1., t_end, valinit=0, valstep=10)\n",
    "\n",
    "slider.on_changed(partial(update_plot, slider, t_step, path_filtered, tracker_filtered))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09fb8c1c",
   "metadata": {},
   "source": [
    "### Observations:\n",
    "- tracker has more time steps than path\n",
    "    - Could get rid of some rows in tracker to avoid costly call to `find_closest_timestamp` and only keep the rows with timestamps closest to the timestamps of path (see filtered dataframes above)\n",
    "- values in 'index' columns increas with each entry\n",
    "- Recording of ~ 2hrs\n",
    "- Tracker circles look smooshed\n",
    "- Affine transformation 'fixes' our smooshed tracker path, but it also scales and shears it"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8dd7899",
   "metadata": {},
   "source": [
    "### How to find offset in timestamps of both datasets relative to each other\n",
    "\n",
    "In order to find deviations of the timestamps (i.e. tracker and path clocks are different), we can use `find_coord_trans()` and and error metric for minimization. We'd need to iterate over different slices of the tracker and path data ([START:END]) and find the two slices with the smallest error.\n",
    "\n",
    "I won't be able to try this because time is running out. It's computationally expensive, so it's best to constrict the slices (e.g. keep a constant slice of the path data and only change the slice of the tracker data within a well-defined region). Also check if the error gets smaller or larger. Only keep going if error gets smaller."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7a13ce94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.39134868  0.29979517 -0.87003969]\n",
      " [-0.90350332  0.05433399  0.42512301]\n",
      " [ 0.17472255  0.95245508  0.2496024 ]]\n",
      "[[-2088.98490866]\n",
      " [ 1908.57798296]\n",
      " [  772.71271809]]\n"
     ]
    }
   ],
   "source": [
    "# Based on https://github.com/nghiaho12/rigid_transform_3D\n",
    "# Finds euclidean 3d translation vectors + rotation matrices (no scaling etc.)\n",
    "def rigid_transform_3D(A, B):\n",
    "    assert A.shape == B.shape\n",
    "\n",
    "    num_rows, num_cols = A.shape\n",
    "    if num_rows != 3:\n",
    "        raise Exception(f\"matrix A is not 3xN, it is {num_rows}x{num_cols}\")\n",
    "\n",
    "    num_rows, num_cols = B.shape\n",
    "    if num_rows != 3:\n",
    "        raise Exception(f\"matrix B is not 3xN, it is {num_rows}x{num_cols}\")\n",
    "\n",
    "    # find mean column wise\n",
    "    centroid_A = np.mean(A, axis=1)\n",
    "    centroid_B = np.mean(B, axis=1)\n",
    "\n",
    "    # ensure centroids are 3x1\n",
    "    centroid_A = centroid_A.reshape(-1, 1)\n",
    "    centroid_B = centroid_B.reshape(-1, 1)\n",
    "\n",
    "    # subtract mean\n",
    "    Am = A - centroid_A\n",
    "    Bm = B - centroid_B\n",
    "\n",
    "    H = Am @ np.transpose(Bm)\n",
    "\n",
    "    # sanity check\n",
    "    #if linalg.matrix_rank(H) < 3:\n",
    "    #    raise ValueError(\"rank of H = {}, expecting 3\".format(linalg.matrix_rank(H)))\n",
    "\n",
    "    # find rotation\n",
    "    U, S, Vt = np.linalg.svd(H)\n",
    "    R = Vt.T @ U.T\n",
    "\n",
    "    # special reflection case\n",
    "    if np.linalg.det(R) < 0:\n",
    "        print(\"det(R) < R, reflection detected!, correcting for it ...\")\n",
    "        Vt[2,:] *= -1\n",
    "        R = Vt.T @ U.T\n",
    "\n",
    "    t = -R @ centroid_A + centroid_B\n",
    "\n",
    "    return R, t\n",
    "\n",
    "R, t = rigid_transform_3D(tracker_filtered[['x', 'y', 'z']].to_numpy().T,\n",
    "                    path_filtered[['x', 'y', 'z']].to_numpy().T) \n",
    "print(R)\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ba51018d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 6.98389191e-01 -1.03778777e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 6.21503371e+00 -6.95162220e-01  0.00000000e+00  0.00000000e+00]\n",
      " [ 6.89135637e-01  2.28459286e-01  0.00000000e+00  0.00000000e+00]\n",
      " [ 2.73641611e+03  1.29991395e+03  0.00000000e+00  1.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "def pad(data):\n",
    "    \"\"\" Adds padding of '1s' as column vector to right side of\n",
    "        data\n",
    "        :param data: nxm data to be padded\n",
    "        :return: returns nx(m+1) padded data\n",
    "    \"\"\"\n",
    "    return np.hstack([data, np.ones((data.shape[0], 1))])\n",
    "\n",
    "def unpad(data):\n",
    "    \"\"\" Removes right most column (can be padding)\n",
    "    :param data: nxm data to be padded\n",
    "    :return: nx(m-1) data\n",
    "    \"\"\"\n",
    "    return data[:,:-1]\n",
    "\n",
    "def transform(data, A):\n",
    "    \"\"\" Applies affine transformation on data with A\n",
    "    :param data: nxm data to be transformed\n",
    "    :param A: Affine (m+1)x(m+1) transformation matrix\n",
    "    :return: transformed data\n",
    "    \"\"\"\n",
    "    return unpad(np.dot(pad(data), A))\n",
    "\n",
    "def compute_max_err(data1, data2):\n",
    "    \"\"\" Computes max norm error of two datasets\n",
    "    \"\"\"\n",
    "    return np.abs(data1 - transform(data2, A)).max()\n",
    "\n",
    "# Affine transformation (also does scaling, shearing, etc.)\n",
    "def find_coord_trans(data1, data2):\n",
    "    \"\"\" Computes approximate affine transformation matrix A\n",
    "    :param data1: first dataset\n",
    "    :param data2: second dataset\n",
    "    :return: Matrix A for which data1 @ A = data2\n",
    "    \"\"\"\n",
    "    Y = pad(data1)\n",
    "    X = pad(data2)\n",
    "    A, res, rank, s = np.linalg.lstsq(X, Y, rcond=None)\n",
    "    A[np.abs(A) < 1e-10] = 0\n",
    "    return A\n",
    "\n",
    "A = find_coord_trans(path_filtered[['x', 'y', 'z']].to_numpy(),\n",
    "                    tracker_filtered[['x', 'y', 'z']].to_numpy()) \n",
    "print(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "49bae36c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Alternatively, transform with affine matrix from find_coord_trans()\n",
    "transformed_tracker = R @ (tracker_filtered[['x', 'y', 'z']].to_numpy().T) + t\n",
    "tracker_transformed = tracker_filtered.copy()\n",
    "tracker_transformed[['x', 'y', 'z']] = transformed_tracker.T\n",
    "slider.on_changed(partial(update_plot, slider, t_step, path_filtered, tracker_transformed))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a26dcd85",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_tracker = transform(tracker_filtered[['x', 'y', 'z']].to_numpy(), A)\n",
    "tracker_affine = tracker_filtered.copy()\n",
    "tracker_affine[['x', 'y', 'z']] = transformed_tracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fd172006",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "ax = plt.subplot(111, label='a')\n",
    "fig.subplots_adjust(left=0.25, bottom=0.25)\n",
    "ax3d = plt.axes(projection='3d', label='b')\n",
    "ax3d.set_xlabel('x')\n",
    "ax3d.set_ylabel('y')\n",
    "ax3d.set_zlabel('z')\n",
    "\n",
    "plt.title('Transformed')\n",
    "\n",
    "t_bias = df_start(path, \"t\", 1e-9)\n",
    "t_end = (df_end(path, \"t\", 1e-9) - t_bias)\n",
    "t_step = df_mean_of_diffs(path, \"t\", 1e-9 )\n",
    "\n",
    "ax_time = plt.axes([0.25, 0.1, 0.65, 0.03])\n",
    "slider = Slider(ax_time, 'Time [sec]', 1., t_end, valinit=0, valstep=10)\n",
    "\n",
    "slider.on_changed(partial(update_plot, slider, t_step, path_filtered, tracker_transformed))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cfbf6612",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Absolute error for each dimension\\n (on transformed tracker data)')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO create subplots for each dimension, so that data doesn't overlap\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.plot(path_filtered['index'].values, np.abs((tracker_transformed['x'].values-path_filtered['x'].values)))\n",
    "plt.plot(path_filtered['index'].values, np.abs((tracker_transformed['y'].values-path_filtered['y'].values)))\n",
    "plt.plot(path_filtered['index'].values, np.abs((tracker_transformed['z'].values-path_filtered['z'].values)))\n",
    "plt.xlabel('sample')\n",
    "plt.ylabel('Absolute error')\n",
    "plt.legend(('x', 'y', 'z'))\n",
    "plt.title(\"Absolute error for each dimension\\n (on transformed tracker data)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf687c3",
   "metadata": {},
   "source": [
    "Please zoom in the data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8577f16d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Absolute error for each dimension\\n (on AFFINE transformed tracker data)')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sorry for copy & pasting the code. Moving it to a function didn't work as expected with matplotlib...\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.plot(path_filtered['index'].values, np.abs((tracker_affine['x'].values-path_filtered['x'].values)))\n",
    "plt.plot(path_filtered['index'].values, np.abs((tracker_affine['y'].values-path_filtered['y'].values)))\n",
    "plt.plot(path_filtered['index'].values, np.abs((tracker_affine['z'].values-path_filtered['z'].values)))\n",
    "plt.xlabel('sample')\n",
    "plt.ylabel('Absolute error')\n",
    "plt.legend(('x', 'y', 'z'))\n",
    "plt.title(\"Absolute error for each dimension\\n (on AFFINE transformed tracker data)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a43c79ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Normalized absolute error for each dimension\\n (on transformed tracker data)')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "plt.bar(np.arange(3), np.array([np.sum(np.abs((tracker_transformed['x'].values-path_filtered['x'].values))),\n",
    "                        np.sum(np.abs((tracker_transformed['y'].values-path_filtered['y'].values))),\n",
    "                        np.sum(np.abs((tracker_transformed['z'].values-path_filtered['z'].values)))])/len(path_filtered),\n",
    "        color=['red', 'blue', 'purple'],\n",
    "        tick_label=['x', 'y', 'z'])\n",
    "\n",
    "plt.ylabel('Normalized error')\n",
    "plt.title(\"Normalized absolute error for each dimension\\n (on transformed tracker data)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9dd4acc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "components  [[-8.00154053e-06 -1.00000000e+00 -0.00000000e+00]\n",
      " [-1.00000000e+00  8.00154053e-06  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  1.00000000e+00]]\n",
      "variance  [7772.00513939 2590.47161907    0.        ]\n",
      "variance ratio  [0.75001424 0.24998576 0.        ]\n",
      "singular values  [33666.34220549 19436.53359256     0.        ]\n",
      "\n",
      "components  [[ 0.90377898 -0.05455428 -0.42450841]\n",
      " [ 0.39074316 -0.29956655  0.87039052]\n",
      " [ 0.17465204  0.95251442  0.24942524]]\n",
      "variance  [7.75843591e+03 2.58506538e+03 8.20964049e-02]\n",
      "variance ratio  [7.50072351e-01 2.49919712e-01 7.93694040e-06]\n",
      "singular values  [33636.94015674 19416.24125833   109.41867805]\n",
      "\n",
      "components  [[-7.08653870e-04 -9.99999749e-01 -8.24081980e-06]\n",
      " [-9.99999729e-01  7.08652211e-04  1.99520007e-04]\n",
      " [ 1.99514117e-04 -8.38220819e-06  9.99999980e-01]]\n",
      "variance  [7.75843591e+03 2.58506538e+03 8.20964049e-02]\n",
      "variance ratio  [7.50072351e-01 2.49919712e-01 7.93694040e-06]\n",
      "singular values  [33636.94015674 19416.24125833   109.41867805]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def get_pca_info(data):\n",
    "    pca = PCA(n_components=3)\n",
    "    pca.fit(data)\n",
    "    print(\"components \", pca.components_)\n",
    "    print(\"variance \", pca.explained_variance_)\n",
    "    print(\"variance ratio \", pca.explained_variance_ratio_)\n",
    "    print(\"singular values \", pca.singular_values_)\n",
    "    print()\n",
    "\n",
    "for df in [path_filtered, tracker_filtered, tracker_transformed]:\n",
    "    get_pca_info(df[['x', 'y', 'z']])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cfbe915",
   "metadata": {},
   "source": [
    "## PCA analysis\n",
    "Less than 0.1% difference in singular values between the tracker and path datasets... Seems like they are the same base on PCA?!\n",
    "\n",
    "But nice to see that explained variance and singular values stayed the same after the euclidean transformation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "629450ee",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Based on the error plot it seems that there are large deviations in x and y direction. Less in z direction. \n",
    "\n",
    "In the non-transformed 3D plot the tracked data looks smooshed, however PCA only showed tiny differences in variance and singular values. Are they the same after all??? Probably not, if the robot arm didn't move correctly. So when it moved, it moved more or less correctly (including the measurement error introduced by the tracking hardware), but sometimes it didn't move correctly at all.\n",
    "\n",
    "The error plots are quite interesting. It seems that there are distinct jumps at certain time stamps (e.g. 56K, 82K, 100K) where the error increases significantly for each sample. After each increase the error per sample never quite reaches the pre-jump values, thus the error increases over time. Something over time must be shifting e.g. maybe the robot arm or tracking system aren't mounted correctly.\n",
    "\n",
    "I couldn't find the 'registration' points, so the coordination transformation was quite tricky to do. \n",
    "\n",
    "Sadly, I'm running out of time and have to stop here. With more time I'd investigate and look at the data in 3D whenever there is a jump in the error value to see what happens then."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
